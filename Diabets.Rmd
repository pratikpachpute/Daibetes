---
output:
  pdf_document: default
  html_document: default
---

```{r message = FALSE}
install.packages("dplyr")
library(dplyr)
glimpse(data)
```


```{r}
getwd()
input_file <- "/Users/pratik/Desktop/ANLY 506 R files/diabetes.csv"
data <- read.csv(input_file)
summary(data)
str(data)
```

#Scaling the data
```{r}
df = scale(data[ , -9])
glimpse(df)
```
#Array of 768 observations and 8 columns



#Method 1 of Clustering using the wssplot script
```{r}
#Running the wssplot.R file by using "source: command
#which has the function "wssplot" with script for ckustering
source('wssplot.R')
```

#or use it from below
```{r}
wssplot <- function(data, nc=15, seed=1234){
  wss <- (nrow(data)-1)*sum(apply(data,2,var))
  for (i in 2:nc){
    set.seed(seed)
    wss[i] <- sum(kmeans(data, centers=i)$withinss)}
  plot(1:nc, wss, type="b", xlab="Number of Clusters",
       ylab="Within groups sum of squares")
  return(wss)}
```

#assinging output of wss funtion to object ncl with data as df(which is the
# data we are using)
```{r}
nc1 <- wssplot(df)
nc1
```

#Method 2 using the NbCLust package to compare with results obtained
#from using the wssplot function file

#Installing Nbclust library and package
```{r include = FALSE}
install.packages("NbClust")
library(NbClust) 
```

```{r}
nc2 <- NbClust(df, min.nc = 2, max.nc = 15, method = "kmeans")
```
# As we see above, NbClust packagegives a side by side graph and the statiscs
#give the majority rule for best number of clusters as 3 clusters


#Using par function to get single Plot mode
```{r}
par(mfrow = c(1,1))
```


#Use nc2$Best.nc to get list of above info of best number of clusters from 
#Nbcluster
```{r}
nc2$Best.nc
```
#Results show many different ways of having the best number of clusters
#Will come back later to it


#Setting up Predictor and Response variable
#Last column is the reponse variable
```{r}
set.seed(6395)
responseY <- data[ ,9]
predictorX <- df[, 1:8]
```


#kmeans() partitions points into k groups so that the sum of squares from each 
#point to the cluster center is minimized.

#Kmeans() uses the Hartigan and Wong (1979) algorithm by default.

# As we have 8 predictors it is not easy to visualize.
#Hence we use PCA to find principal components and conduct Kmeans using these
#Principal components rather than using the Kmeans on entire 8 dimensional
#Data set object predictorX

#Using prncomp() command for PCA.
#The princomp() command is a bit different than the prcomp() command 
#It is somewhat less stable but provides much more information
#For the princomp() function to work on the correlation table, set cor=T.
```{r}
pca <- princomp(predictorX, cor = T)
pca$sdev
```


#To get the variance, or the amount of the original data accounted for by
#each principle component we need only to square the standard deviations. 
#But, this can actually be misleading using the information generated by the 
#princomp() or even the prcomp() commands in R.

#It is better to use the summary() command to look at the overall variance, 
#or how much each principle component explains of the variance in the data.
```{r}
summary(pca)
```


# Now, we need to and can decide how many principle components to use in our 
#analysis. If we just use the first two principle components then:
```{r}
pc.comp <- pca$scores
pc.comp1 <- pc.comp[ , 1]
pc.comp2 <- pc.comp[ , 2]
x <- cbind(pc.comp1, pc.comp2)
```


#Many ways to proceed with no of clusters and PC. So we proceed with Kmeans() to
#plot the clusters along with thier centers.
#There are 8 predictor variables and these can cluster in many ways to predict
#diabetes although diabetes has just responses yes or no & hence just 2 clusters

# let us proceed looking at variety of number of clusters.
#Let us start with 2 clusters.
```{r}
set.seed(1234)
cl <- kmeans(x,2)
plot(pc.comp1, pc.comp2, col = cl$cluster)
points(cl$centers, pch=16, col = "green")
```


#With 3 clusters
```{r}
set.seed(2345)
cl <- kmeans(x, 3)
plot(pc.comp1, pc.comp2, col=cl$cluster)
points(cl$centers, pch=16, col="blue")
```


#Again with eight  clusters as follows
```{r}
set.seed(3456)
cl <- kmeans(x, 8)
plot(pc.comp1, pc.comp2, col = cl$cluster)
points(cl$centers, pch=16, col = "cyan")
```

#With 13 clusters
```{r}
set.seed(4567)
cl <- kmeans(x, 13)
plot(pc.comp1, pc.comp2, col = cl$cluster)
points(cl$centers, pch=16)
```

#Can list the location of 13 cluster centers from above using the command:
```{r}
cl$centers
```
#As we see it gave a table for pc.comp1 and pc.comp2 for 13 clusters as selected
#These are the locations that are plotted as the points on plots.
#We can assign the results of each of these calculations to a different object
#to easily make comparisons between them.

#can assign the output of these tables to different objects for comparison.
```{r}
table(data$Outcome, cl$cluster)
```
#   1  2  3  4  5  6  7  8  9 10 11 12 13
#0 12 28 75 65 29 55 22  5 90 56 41 17  5
#1  1 34 27 14 22 25 32  8  6  9 40 13 37

#As we see above the tables shows the frequencies of yes(1) and no(0)
#for the 13 clusters as we selected.

